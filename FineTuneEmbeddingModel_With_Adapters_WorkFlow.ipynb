{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Add-Vishnu/Finetuning-Embedding-models/blob/main/FineTuneEmbeddingModel_With_Adapters_WorkFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finetuning the embedding model**"
      ],
      "metadata": {
        "id": "CcdASouW0USN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Generating Synthetic Data for Training and Evaluation"
      ],
      "metadata": {
        "id": "BluNvwDG0fGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**i) Generating corpus**\n",
        "\n",
        "-> You can load the documents and create nodes using the llamaindex\n",
        "\n",
        "-> or if you have the data like name_of_document, page_no and content you can directly create the corpus dictionary .\n",
        "\n",
        "corpus = { node_id : node_content }\n",
        "\n",
        "->  If created using llamaindex , node_id will be the node.id. If you already have the data you have create your custom node_id. Eg: node_id can be comnination of name_of_document and page_no.\n",
        "\n",
        "-> Content will be the node.content if you created nodes of documents using llamaindex. or they can be the content you have, but make sure document with that page number have that content."
      ],
      "metadata": {
        "id": "SEToBWfw0zSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMhu_3UN0PmM"
      },
      "outputs": [],
      "source": [
        "# your own corpus\n",
        "corpus = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ii) Generating Synthetic queries**\n",
        "\n",
        "-> You can use LLM to genrate questions for each text chunk in the corpus and create the `queries` and `relevant_docs` dictionaries.\n",
        "\n",
        "-> `queries` dictionary should have a query_id which can be generated using `uuid` and the value will be the Question.\n",
        "\n",
        "**`queries[query_id] = question`**\n",
        "\n",
        "-> `relevant_docs` dictionary have key as the `query_id` and the values will be the list of `node_ids`.\n",
        "\n",
        "**`relevant_dosc[question_id] = [node_id]`**\n",
        "\n",
        "**Note**:\n",
        "\n",
        "If you already have the questions, relevant docs i.e name of the document and page no., you can combine those information and create these dictionaries.\n",
        "\n",
        "-> Split the dataset into training and validation datasets, and you can create a function to create these dictionaries and and pass each datasets(train,val) one by one.\n",
        "\n",
        "`train_corpus`\n",
        "\n",
        "`val_corpus`"
      ],
      "metadata": {
        "id": "CoxIxF3U2Ntr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = # Use your data\n",
        "val_corpus = # Use your data"
      ],
      "metadata": {
        "id": "JnMdRSSf54rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the function which return queries and relevant_docs dictionary\n",
        "def generate_queries(faq_corpus):\n",
        "  queries = {}\n",
        "  relevant_docs = {}\n",
        "\n",
        "  # Implement you logic here\n",
        "\n",
        "  return queries,relevant_docs"
      ],
      "metadata": {
        "id": "PLzlWHgh2XD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_queries, train_relevant_docs = generate_queries(train_corpus)\n",
        "val_queries, val_relevant_docs = generate_queries(val_corpus)"
      ],
      "metadata": {
        "id": "fDHP57Nr5nT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**iii) Merge Data**:\n",
        "\n",
        "-> Creating the training and validation dataset using the data you have.\n",
        "\n",
        "**`train_dataset = {\n",
        "            'queries' : train_queries ,\n",
        "            'corpus' : corpus,\n",
        "            'relevant_docs' : train_relevant_docs,\n",
        "    }`**\n",
        "\n",
        "\n",
        "**`val_dataset = {\n",
        "            'queries' : val_queries ,\n",
        "            'corpus' : corpus,\n",
        "            'relevant_docs' : val_relevant_docs,\n",
        "    }`**\n",
        "\n",
        "If you split the train and val datasets from the same data, then the corpus will be the same"
      ],
      "metadata": {
        "id": "JIZVJt3u4Bn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = {\n",
        "    'queries': train_queries,\n",
        "    'corpus': corpus,\n",
        "    'relevant_docs': train_relevant_docs,\n",
        "}\n",
        "\n",
        "val_dataset = {\n",
        "    'queries': val_queries,\n",
        "    'corpus': corpus,\n",
        "    'relevant_docs': val_relevant_docs,\n",
        "}"
      ],
      "metadata": {
        "id": "jm1PW-dz4Fy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) Finetuning the embedding model using LLamaindex**"
      ],
      "metadata": {
        "id": "JnLXknIt6PTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Save the train_dataset and val_dataset into json files**\n",
        "\n"
      ],
      "metadata": {
        "id": "bWNjlTp26hV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Save train_dataset and val_dataset as JSON files\n",
        "with open(\"train_dataset.json\", \"w\") as train_file:\n",
        "    json.dump(train_dataset, train_file)\n",
        "\n",
        "with open(\"val_dataset.json\", \"w\") as val_file:\n",
        "    json.dump(val_dataset, val_file)"
      ],
      "metadata": {
        "id": "6qHKEr9t6dDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load them using the EmbeddingQAFinetuningDataset"
      ],
      "metadata": {
        "id": "dOflfl3U6uGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
        "\n",
        "\n",
        "train_dataset_ll = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
        "val_dataset_ll = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
      ],
      "metadata": {
        "id": "Vj3SjMO06sqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the object for `SentenceTransformersFinetuneEngine` and pass the train_dataset, model_name, model_output_path, val_dataset."
      ],
      "metadata": {
        "id": "NjeytNq361Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"BAAI/bge-small-en\",\n",
        "    model_output_path=\"test_model\",\n",
        "    val_dataset=val_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "_aVxgJD87PO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetune the model by calling the finetune method"
      ],
      "metadata": {
        "id": "1IzghLI47SLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_engine.finetune()"
      ],
      "metadata": {
        "id": "YpkJZ95N7VWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **Finetuning Linear adapter on top of fine tuned embedding model**\n"
      ],
      "metadata": {
        "id": "XSYAGdVXQtv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n",
        "from llama_index.embeddings import resolve_embed_model\n",
        "import torch\n",
        "\n",
        "base_embed_model = resolve_embed_model(\"local:/test_model\") # path_to_finetuned_model\n"
      ],
      "metadata": {
        "id": "P94gEl7Kwqtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_engine_adapter = EmbeddingAdapterFinetuneEngine(\n",
        "    train_dataset_ll,\n",
        "    base_embed_model,\n",
        "    model_output_path=\"/test_adapter_onFinetuned\",\n",
        "    # bias=True,\n",
        "    epochs=4,\n",
        "    verbose=False,\n",
        "    optimizer_class=torch.optim.SGD,\n",
        "    optimizer_params={\"lr\": 0.01}\n",
        ")"
      ],
      "metadata": {
        "id": "H5lMIhVTwqqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_engine_adapter.finetune()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "cc7e1c060ad24702896c1655055768a6",
            "c4b569b9fc8f46c8936687e6107f5c83",
            "19da3cd980704dadb59ab5cb2aaba688",
            "c27c308a36f34a4aaca1ac459376fdec",
            "84c6cafd662a480aa93c08c045342783",
            "1cbb1d1d9dce46eb91df69b3b54d98e5",
            "e34f6937c7ba4bbe96d14619bfa23426",
            "971628b67fa542fe80fb49ace0c34e53",
            "a435264365c64ba1878070b22e373678",
            "2ffadbf453a54466bea8894e486c72fa",
            "9815bac791344012978842f499d795a4",
            "26eaae016f9f43daa6d8c91bf82e6ee6",
            "8e9aebda23b34c7c9d3bdfd44542a0f3",
            "19205ba5574f42859d7abf767b873fe9",
            "b79421554a044c15ae037a8c5f335c93",
            "c6bc9d1bb666486081be31c1573eeef6",
            "ff992e9f0a17403b97623b19cf298e0b",
            "855580813a1e42499874e96ce2bacd8d",
            "9d27c231a80c450ea95716f45d499845",
            "635dd1f8eaee40e9bc82bfbc35ef404b",
            "d7ffbb58fb2041f99a220689c2490db1",
            "96db028dcd604f07bab2bf8a7f744ed7",
            "9dde7a58d5fe4c4b823c588b2f74ce8c",
            "d7d1dfff6b8b43478e24b0d753aa5686",
            "9d37c5b7040345d2b7d0f093d2be44ea",
            "07ebe210be494b3387006bb9983885da",
            "3a56e7701cdb460aa4a9375f9d363034",
            "28907c068111432f8f3a0143afa90a5e",
            "6e4b5da2a56245fe925855cd80b716bd",
            "e98a577d2327480cb6a3d648cfe9014b",
            "0e5ce133a88945c9893e5a6191e63210",
            "2f4beb78241e446db896dc70c7c88bbb",
            "bb5529c15744486688be5dedfb9f21f5",
            "9e67f446ea854e47ae21a0de0c2944f0",
            "29221165e8c5458cacf00dfcb0543e68",
            "4ad5fe07ae934366981ee3a90e3e2f16",
            "83ab680a676e49caaa2ec14f70b2afde",
            "b9967613d5be48fcb68c970e1f1b333f",
            "744b4fc5b9a2416a9a2baf7cf680290d",
            "d8102c220f794bb59687bcf30d466d30",
            "d151a8c0ea69469db0d11a858bb93da8",
            "a89baf3725f34ee092ce65d2d5242d30",
            "1632a6b1cef34f51a87fbe6e62353005",
            "68fe7650056a4a9588b3b0cc8b4560bd",
            "1e16ebd9f52c4ab5bd99401ed0b886fc",
            "3d28615757444728be9164434b58ded6",
            "edab9148405846d096f415c52ecf0ca3",
            "3dc443675c96444387c782c9f20cbcca",
            "f6a64f12915c4341b12a6b2bc8229a45",
            "7233be264e5f43a6b06e05f33c773d1a",
            "89283a4fa99b4df8acbb045fa6152eec",
            "492ab86730ec4890b6128ea9991bd375",
            "f657db22f6e941b39505ea4a02d8513b",
            "bfbe265ae1814898ab3943b2bbb20b18",
            "bb1690cd3aec477db134887215a104cf"
          ]
        },
        "id": "6v36n7wSwqoR",
        "outputId": "cb76967c-a0e7-42b0-fdd3-1d41a7430828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc7e1c060ad24702896c1655055768a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iteration:   0%|          | 0/315 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26eaae016f9f43daa6d8c91bf82e6ee6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iteration:   0%|          | 0/315 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dde7a58d5fe4c4b823c588b2f74ce8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iteration:   0%|          | 0/315 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e67f446ea854e47ae21a0de0c2944f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iteration:   0%|          | 0/315 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e16ebd9f52c4ab5bd99401ed0b886fc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) Evaluate the fine-tune model**"
      ],
      "metadata": {
        "id": "P6_ygwZK7XIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext, VectorStoreIndex\n",
        "from llama_index.schema import TextNode\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uUTgUYBb7cqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funtion for hit rate.\n",
        "\n",
        "The arguments it takes are `dataset` , `embedding model` , `top_k` and returns a dictionary of evaluation results containing\n",
        "\n",
        "`eval_result = {\n",
        "            \"is_hit\": is_hit,\n",
        "            \"retrieved\": retrieved_ids,\n",
        "            \"expected\": expected_ids,\n",
        "            \"query\": query_id,\n",
        "        }`"
      ],
      "metadata": {
        "id": "f6byQhgk7nkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    dataset,\n",
        "    embed_model,\n",
        "    top_k=5,\n",
        "    verbose=False,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(embed_model=embed_model,llm=None)\n",
        "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
        "    index = VectorStoreIndex(nodes, service_context=service_context, show_progress=True)\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    eval_results = []\n",
        "    for query_id, query in tqdm(queries.items()):\n",
        "        retrieved_nodes = retriever.retrieve(query)\n",
        "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
        "        expected_ids = relevant_docs[query_id]\n",
        "        # is_hit = expected_ids in retrieved_ids  # assume 1 relevant doc\n",
        "\n",
        "\n",
        "        retrieved_set = set(retrieved_ids)\n",
        "        expected_set = set(expected_ids)\n",
        "        common_nodes = retrieved_set.intersection(expected_set)\n",
        "        is_hit = len(common_nodes) > 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        eval_result = {\n",
        "            \"is_hit\": is_hit,\n",
        "            \"retrieved\": retrieved_ids,\n",
        "            \"expected\": expected_ids,\n",
        "            \"query\": query_id,\n",
        "        }\n",
        "        eval_results.append(eval_result)\n",
        "        # break\n",
        "    return eval_results"
      ],
      "metadata": {
        "id": "-0C1uwXP7jr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for evaluating using the `InformationRetrievalEvaluatoe` of sentence transformers.\n"
      ],
      "metadata": {
        "id": "P8vyC7oi8KdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "def evaluate_st(\n",
        "    dataset,\n",
        "    model_id,\n",
        "    name,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n",
        "    model = SentenceTransformer(model_id)\n",
        "    return evaluator(model, output_path=\"results/\")"
      ],
      "metadata": {
        "id": "sNXaIsU38J1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the original model with the val_dataset."
      ],
      "metadata": {
        "id": "QC0hcFN48XhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation using hit rate for original bge model"
      ],
      "metadata": {
        "id": "ejWYBkbm8wSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bge = \"local:BAAI/bge-small-en\"\n",
        "bge_val_results = evaluate(val_dataset_ll, bge)   # hit rate"
      ],
      "metadata": {
        "id": "Sqrxlysr8dJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe\n",
        "df_bge = pd.DataFrame(bge_val_results)\n",
        "# Calculate the mean of all the hitrates for each node\n",
        "hit_rate_bge = df_bge['is_hit'].mean()\n",
        "hit_rate_bge"
      ],
      "metadata": {
        "id": "8q5Y5d0A8jKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation using InformationRetirevalEvaluator for original bge model"
      ],
      "metadata": {
        "id": "mBAErPIP8zPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_st(val_dataset_ll, \"BAAI/bge-small-en\", name='bge')"
      ],
      "metadata": {
        "id": "po6ztdyN8zyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Finetuned model with the val_dataset."
      ],
      "metadata": {
        "id": "8PSYJr9B82Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation using hit rate for finetuned model"
      ],
      "metadata": {
        "id": "N-SSIr5v8-gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned = \"local:test_model\"\n",
        "val_results_finetuned = evaluate(val_dataset_ll, finetuned) # hit rate"
      ],
      "metadata": {
        "id": "se5Gw2DX86O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_finetuned = pd.DataFrame(val_results_finetuned)\n",
        "hit_rate_finetuned = df_finetuned['is_hit'].mean()\n",
        "hit_rate_finetuned"
      ],
      "metadata": {
        "id": "02LgA85o9En8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation using InformationRetirevalEvaluator for finetuned bge model"
      ],
      "metadata": {
        "id": "KkXwDZVp9Ipo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_st(val_dataset_ll, \"test_model\", name='finetuned')"
      ],
      "metadata": {
        "id": "2gF1pPKm9H1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Finetuned adapter with the val_dataset."
      ],
      "metadata": {
        "id": "DedLikmQd7tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation using hit rate for finetuned adapter"
      ],
      "metadata": {
        "id": "QhKlLw2ad7t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adapter = \"local:test_adapter_onFinetuned\"\n",
        "val_results_adapter = evaluate(val_dataset_ll, adapter) # hit rate"
      ],
      "metadata": {
        "id": "IShw-uY8d7t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_adapter = pd.DataFrame(val_results_adapter)\n",
        "hit_rate_adapter = df_adapter['is_hit'].mean()\n",
        "hit_rate_adapter"
      ],
      "metadata": {
        "id": "s0zd-V11d7t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation using InformationRetirevalEvaluator for finetuned adapter on top of finetuned embedding model"
      ],
      "metadata": {
        "id": "P_PiJvJpd7t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_st(val_dataset_ll, \"test_adapter_onFinetuned\", name='adapter')"
      ],
      "metadata": {
        "id": "H5cDqeZRd7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of evaluation"
      ],
      "metadata": {
        "id": "J44peYzD9OFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hit rate"
      ],
      "metadata": {
        "id": "BJBU40Zm9Y4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bge['model'] = 'bge'\n",
        "df_finetuned['model'] = 'fine_tuned'\n",
        "df_adapter['model'] = 'fine_tuned_adapter'"
      ],
      "metadata": {
        "id": "ZidipjdE9Qd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.concat([df_bge, df_finetuned,df_adapter])\n",
        "df_all.groupby('model').mean('is_hit')"
      ],
      "metadata": {
        "id": "TgJP9PD09T2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InformationRetrievalEvaluator"
      ],
      "metadata": {
        "id": "tkHH5g5E9aCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_st_bge = pd.read_csv('results/Information-Retrieval_evaluation_bge_results.csv')\n",
        "df_st_finetuned = pd.read_csv('results/Information-Retrieval_evaluation_finetuned_results.csv')\n",
        "df_st_adapter = pd.read_csv('results/Information-Retrieval_evaluation_adapter_results.csv')\n",
        "\n",
        "df_st_bge['model'] = 'bge'\n",
        "df_st_finetuned['model'] = 'fine_tuned'\n",
        "df_st_adapter['model'] = 'fine_tuned_adapter'\n",
        "df_st_all = pd.concat([df_st_bge, df_st_finetuned, df_st_adapter])\n",
        "df_st_all = df_st_all.set_index('model')\n",
        "df_st_all\n"
      ],
      "metadata": {
        "id": "9nj3BH1c9cWU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}